[
  {
    "path": "posts/ir_nls/",
    "title": "Learning to Rank in the era of transformers",
    "description": "With the advent of advances in NLP, Ranking of search results is increasingly a NLP problem. This post will give an insight into basics as well as the most recent advances.",
    "author": [
      {
        "name": "Nikhil Kasukurthi",
        "url": "https://example.com/norajones"
      }
    ],
    "date": "2021-05-28",
    "categories": [],
    "contents": "\n\nContents\nProblem at hand\nDataset\nEvaluation criteria for Ranking\nDiscounted Cumulative Gains (DCG)\nMean Rank Reciprocal (MRR)\n\nLearning to Rank - 101\nPointwise Ranking\nPairwise Ranking\nListwise Ranking\n\nTraditional Ranking appraoches\nRankNet and LambdaRank\nLambdaMART\n\nDeep nerual network approaches\nDeep Structured Semantic Model (DSSM) for websearch using clickthrough data.\nDRRM\nDeText\n\nAcknowledgments\n\nProblem at hand\nThroughout this post, we will be discussing this from the lens of e-commerce website, building a search engine for the user to search the product.\nIn the figure, you can see it clearly, a user has a rough idea of the products they are looking for. This problem can be modeled in the following way.\nintroductionDataset\nThe dataset for this type of problems is typically collected by mining the logs of user-clicks. A product that the user clicks is considered a positive and ranked higher. Other methods use a human annotator for ranking the relevance of a set of documents given a query.\nEvaluation criteria for Ranking\nBefore we dive into how to solve the problem, establishing the criteria to evaluate it is important. In this case, the relevance of ranked documents to the user is the primary criteria. There are multiple methods of doing it, the usual precision, recall and f-score are some methods. For IR specifically, Discounted Cumulative Gains (DCG), it’s normalized form NDCG, Mean Rank Reciprocal are used. We will be discussing them further here.\nDiscounted Cumulative Gains (DCG)\nMean Rank Reciprocal (MRR)\nLearning to Rank - 101\nThe basis of ranking is rooted in three basic approaches of loss calculation. Namely Pointwise, Pairwise and Listwise ranking.\nFormalizing the problem, we have a set of queries \\(Q=\\{q_1,q_2....q_n\\}\\), for which we need to retrieve a set of relevant documents \\(D=\\{d_1, d_2,...d_k\\}\\); Each of the above approaches treats this problem differently.\nPointwise Ranking\nIn this setting, each document with respect to the query is treated independently. Given a query, all the documents are given a score of relevance.\nPairwise Ranking\nTwo documents are taken in conjunction and their precedence is predicted.\nListwise Ranking\nThe above two approaches do not take into account the inter-document relationship, its assumed that all the documents are independent.\nListwise approaches are the closest to modeling the metrics that we had defined earlier.\nTraditional Ranking appraoches\nQuery depedent methods typically use TF-IDF [cite this] or another popular LR related approach is BM25 1 [cite this].\nHere we discuss some of the seminal works.\nRankNet and LambdaRank\nThese are pairwise approaches. In RankNet, the query \\(q_i\\) and document \\(d_k\\) features are concatenated and fed through the model. The output for a pair of query-document \\(f(q_i,d_1)\\) and \\(f(q_i,d_2)\\) is compared. The network gives a relevance score to each document and the document with the higher score is given precedence. Once it’s done for all pair of documents, they are sorted in their order of relevance. The model is trained with a cross-entropy loss. Drawback of RankNet is that the model optimizes for only document pairs but our metric to evaluate DCG, evaluates the relative ranking of documents. The penalty for incorrectly ranking the first two documents will be higher than that of last two documents.\nLambdaRank is an extension of RankNet, mitigating the optimization for DCG metric by adding a \\(delta\\) of the NDCG score if the\nLambdaMART\nThrough gradient boosted trees, LambdaMart looks at the entire set of documents i.e., it’s a listwise ranking. They are branched based on their features and the results are aggregated from all the trees to give a final relevance prediction for each document.\nThe progression of has been from RankNet then to LambdaRank and to LambdaMART\nDeep nerual network approaches\nDeep Structured Semantic Model (DSSM) for websearch using clickthrough data.\n\nIn case of RankNet, the relevance scores of each query-document is computed and ranked accordingly. But with DSSM, the embeddings for bag-of-words vectors of query and documents are computed independently but from the same model. Then the cosine similarity with the query embedding and document is calculated for the semantic relevance score. The documents are sorted based on this score.\ndssm-overviewTo train the network, a posterior probability is computed for the document given a query from the semantic relevance score between them through a softmax function. Random negative samples are included in a minibatch i.e., a completely irrelevant document and a relevant document are sampled and trained with a cross-entropy loss.\nDSSM also uses word-hashing to tackle the large dimensionaltiy introduced when working with a web-scale vocabulary by using an MLP layer as shown in figure.\ndssm-archDRRM\nTODO\nDeText\nDeText is a flexible pipeline that was built to rank LinkedIn’s user profiles, jobs and help FAQs based on search queries. In the techniques described above,\nAcknowledgments\n\n25 because it was the 25th formula that had worked for them.↩︎\n",
    "preview": {},
    "last_modified": "2021-05-28T18:25:51+05:30",
    "input_file": "info_retrival_nls.utf8.md"
  }
]
