[
  {
    "path": "posts/ir_nls/",
    "title": "Learning to Rank in the era of transformers",
    "description": "With the advent of advances in NLP, Ranking of search results is increasingly a NLP problem. This post will give an insight into basics as well as the most recent advances.",
    "author": [
      {
        "name": "Nikhil Kasukurthi",
        "url": "https://example.com/norajones"
      }
    ],
    "date": "2024-06-15",
    "categories": [
      "NLP",
      "Search Ranking",
      "Deep Dive"
    ],
    "contents": "\n\nContents\nProblem at hand\nDataset\nEvaluation criteria for Ranking\nDiscounted Cumulative Gains (DCG)\nMean Rank Reciprocal (MRR)\n\nLearning to Rank - 101\nPointwise Ranking\nPairwise Ranking\nListwise Ranking\n\nTraditional Ranking appraoches\nRankNet and LambdaRank\nLambdaMART\n\nDeep nerual network approaches\nDeep Structured Semantic Model (DSSM) for websearch using clickthrough data.\nDRMM\nDeText\nGraph-based multilingual product retrival in E-commerce search\n\nAcknowledgments\n\nProblem at hand\nThroughout this post, we will be discussing this from the lens of e-commerce website, building a search engine for the user to search the product.\nIn the figure, you can see it clearly, a user has a rough idea of the products they are looking for.\nThis problem can be modeled in the following way.\n\n\nShow code\n\nlibrary(knitr)\ninclude_graphics(\"images/introduction.gif\")\n\n\n\nFigure 1: Introduction\n\n\n\n\nDataset\nThe dataset for this type of problems is typically collected by mining the logs of user-clicks.\nA product that the user clicks is considered a positive and ranked higher. Other methods use a human annotator for ranking the relevance of a set of documents given a query.\nEvaluation criteria for Ranking\nBefore we dive into how to solve the problem, establishing the criteria to evaluate it is important.\nIn this case, the relevance of ranked documents to the user is the primary criteria.\nThere are multiple methods of doing it, the usual precision, recall and f-score are some methods.\nFor IR specifically, Discounted Cumulative Gains (DCG), it’s normalized form NDCG, Mean Rank Reciprocal are used.\nWe will be discussing them further here.\nDiscounted Cumulative Gains (DCG)\nMean Rank Reciprocal (MRR)\nLearning to Rank - 101\nThe basis of ranking is rooted in three basic approaches of loss calculation.\nNamely Pointwise, Pairwise and Listwise ranking.\nFormalizing the problem, we have a set of queries \\(Q=\\{q_1,q_2....q_n\\}\\), for which we need to retrieve a set of relevant documents \\(D=\\{d_1, d_2,...d_k\\}\\); Each of the above approaches treats this problem differently.\nPointwise Ranking\nIn this setting, each document with respect to the query is treated independently.\nGiven a query, all the documents are given a score of relevance.\nPairwise Ranking\nTwo documents are taken in conjunction and their precedence is predicted.\nListwise Ranking\nThe above two approaches do not take into account the inter-document relationship, its assumed that all the documents are independent.\nListwise approaches are the closest to modeling the metrics that we had defined earlier.\nThe entire group of documents are considered for ranking\nTraditional Ranking appraoches\nQuery depedent methods typically use TF-IDF [cite this] or another popular LR related approach is BM25 1 [cite this].\nHere we discuss some of the seminal works.\nRankNet and LambdaRank\nThese are pairwise approaches.\nIn RankNet, the query \\(q_i\\) and document \\(d_k\\) features are concatenated and fed through the model.\nThe output for a pair of query-document \\(f(q_i,d_1)\\) and \\(f(q_i,d_2)\\) is compared.\nThe network gives a relevance score to each document and the document with the higher score is given precedence.\nOnce it’s done for all pair of documents, they are sorted in their order of relevance.\nThe model is trained with a cross-entropy loss.\nDrawback of RankNet is that the model optimizes for only document pairs but our metric to evaluate DCG, evaluates the relative ranking of documents.\nThe penalty for incorrectly ranking the first two documents will be higher than that of last two documents.\nLambdaRank is an extension of RankNet, mitigating the optimization for DCG metric by adding a \\(delta\\) of the NDCG score if the\nLambdaMART\nThrough gradient boosted trees, LambdaMart looks at the entire set of documents i.e., it’s a listwise ranking.\nThey are branched based on their features and the results are aggregated from all the trees to give a final relevance prediction for each document.\nThe progression of has been from RankNet then to LambdaRank and to LambdaMART\nDeep nerual network approaches\nDeep Structured Semantic Model (DSSM) for websearch using clickthrough data.\n\nIn case of RankNet, the relevance scores of each query-document is computed and ranked accordingly.\nBut with DSSM, the embeddings for bag-of-words vectors of query and documents are computed independently but from the same model.\nThen the cosine similarity with the query embedding and document is calculated for the semantic relevance score.\nThe documents are sorted based on this score.\n\n\nShow code\n\nlibrary(knitr)\ninclude_graphics(\"images/Dssm-overview.jpg\")\n\n\n\nFigure 2: DSSM Overview\n\n\n\nTo train the network, a posterior probability is computed for the document given a query from the semantic relevance score between them through a softmax function.\nRandom negative samples are included in a minibatch i.e., a completely irrelevant document and a relevant document are sampled and trained with a cross-entropy loss.\nDSSM also uses word-hashing to tackle the large dimensionaltiy introduced when working with a web-scale vocabulary by using an MLP layer as shown in figure.\n\n\nShow code\n\nlibrary(knitr)\ninclude_graphics(\"images/Dssm-arch.jpg\")\n\n\n\nFigure 3: DSSM Architecture\n\n\n\nDRMM\nTODO\nDeText\nDeText is a flexible pipeline that was built to rank LinkedIn’s user profiles, jobs and help FAQs based on search queries.\nThrough a custom trained bert - LiBert on LinkedIn, the raking is performed.\nUnlike other approaches, DeText is capable of taking in multiple fields of entries.\n\n\nShow code\n\nlibrary(knitr)\ninclude_graphics(\"images/detext-arch.png\")\n\n\n\nFigure 4: DeText Architecture\n\n\n\n\n\nShow code\n\nlibrary(knitr)\ninclude_graphics(\"images/detext-inference.png\")\n\n\n\nFigure 5: DeText Inference Pipeline\n\n\n\nGraph-based multilingual product retrival in E-commerce search\nThe amazon search ranking incorporates a Graph Neural Network in tandem with a transformer encoder.\nThe transformer is trained with both the query and documents.\nTraining\nThey train a DistillBERT with 6 layers and 768 hidden units.\n\n\nShow code\n\nlibrary(knitr)\ninclude_graphics(\"images/amazon-graph-ranking.png\")\n\n\n\nFigure 6: Architecture\n\n\n\nInference\nDuring inference, similar to DSSM, they compute cosine similarity between the query embedding and document (product) embeddings.\nThen finding K-Nearest Neighbors of the query. (check this)\nAcknowledgments\n\n25 because it was the 25th formula that had worked for them.↩︎\n",
    "preview": "posts/ir_nls/images/introduction.gif",
    "last_modified": "2024-06-15T11:01:15+05:30",
    "input_file": "info_retrival_nls.knit.md"
  },
  {
    "path": "posts/retrieval-with-es/",
    "title": "Retrieval with ElasticSearch for LLMs",
    "description": "The `R` in RAG is very critical, the current popular methods of embed docuemnts and compare with query are very expensive.",
    "author": [
      {
        "name": "Nikhil Kasukurthi",
        "url": "https://example.com/norajones"
      }
    ],
    "date": "2024-06-15",
    "categories": [],
    "contents": "\nDistill is a publication format for scientific and technical writing, native to the web.\nLearn more about using Distill for R Markdown at https://rstudio.github.io/distill.\n\n\n\n",
    "preview": {},
    "last_modified": "2024-06-15T11:17:50+05:30",
    "input_file": "post.knit.md"
  },
  {
    "path": "posts/introduction/",
    "title": "Introduction to wawn.io",
    "description": "When and When Not",
    "author": [
      {
        "name": "Nikhil Kasukurthi",
        "url": {}
      }
    ],
    "date": "2021-05-31",
    "categories": [],
    "contents": "\nWhen and When Not\nMore often than not, there are multiple ways to solve a problem. And most developers and data scientists learn on the job, for the job. This means that at times, we might be learning part of a whole, that is pertinent to task at hand.\nAlthough this approach is quick and gets the job done, sometimes you can’t help but wonder, what’s the right way of doing this? or what are the alternative ways of doing this.\nhttps://wawn.io is just the place for that.\nMost experienced developers almost always say the largest learning they had are through their colleagues or friends. https://wawn.io is a place to formalize that knowledge as well. The long term plan on different types of posts is something like this.\nDifferent ways of doing a similar thing.\nLearning the basics, with directions to the resources.\nIn depth surveys of a method, exploring the genesis to the most recent advances of a method.\n\n\n\n",
    "preview": {},
    "last_modified": "2021-06-01T09:06:41+05:30",
    "input_file": {}
  }
]
